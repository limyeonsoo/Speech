{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Test a pretrained CNN for Google speech commands.\"\"\"\n",
    "\n",
    "__author__ = 'Yuan Xu, Erdene-Ochir Tuguldur'\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import *\n",
    "import torchnet\n",
    "\n",
    "from datasets import *\n",
    "from transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "\n",
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, bias=False):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_planes, in_planes, kernel_size=kernel_size, stride=stride, groups=in_planes, bias=bias, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.pointwise = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, bias=bias)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.pointwise(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = depthwise_separable_conv(inplanes, planes, 3, stride)\n",
    "        self.conv2 = depthwise_separable_conv(planes, planes, 3)\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        #print(\"out {}\".format(out.shape))\n",
    "        #print(\"res {}\".format(residual.shape))\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, in_channels=2):\n",
    "        self.inplanes = 45\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, self.inplanes, kernel_size=3, stride=1, bias=False, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(4, 3), stride=1)\n",
    "        self.layer1 = self._make_layer(block, 45, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 45, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 45, layers[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(45, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        #print(downsample)\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #x = self.layer4(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arg():\n",
    "    def __init__(self):\n",
    "        self.dataset_dir = \"/home/cilab/LabMembers/DJ/sr_dataset/speech_commands_dataset/splitted_data/test\"\n",
    "        #self.dataset_dir = \"/home/cilab/LabMembers/DJ/sr_dataset/speech_command/test\"\n",
    "        self.batch_size = 128\n",
    "        self.dataload_workers_nums = 3\n",
    "        self.input = \"mel40\"\n",
    "        self.multi_crop = True\n",
    "        self.model = \"./1574053961987-ds-resnet18_sgd_plateau_bs64_lr1.0e-02_wd1.0e-02-best-acc.pth\"\n",
    "\n",
    "args = Arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=(4, 3), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): depthwise_separable_conv(\n",
      "          (depthwise): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=45, bias=False)\n",
      "          (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (pointwise): Conv2d(45, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=45, out_features=12, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"loading model...\")\n",
    "model = torch.load(args.model)\n",
    "model.float()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38712"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu True\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('use_gpu', use_gpu)\n",
    "if use_gpu:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model.cuda()\n",
    "\n",
    "n_mels = 32\n",
    "if args.input == 'mel40':\n",
    "    n_mels = 40\n",
    "\n",
    "dataset_dir = args.dataset_dir\n",
    "feature_transform = Compose([ToMelSpectrogram(n_mels=n_mels), ToTensor('mel_spectrogram', 'input')])\n",
    "transform = Compose([LoadAudio(), FixAudioLength(), feature_transform])\n",
    "test_dataset = SpeechCommandsDataset(dataset_dir, transform, silence_percentage=0.3)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, sampler=None,\n",
    "                            pin_memory=use_gpu, num_workers=args.dataload_workers_nums)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_crop(inputs):\n",
    "    b = 1\n",
    "    size = inputs.size(3) - b * 2\n",
    "    patches = [inputs[:, :, :, i*b:size+i*b] for i in range(3)]\n",
    "    outputs = torch.stack(patches)\n",
    "    outputs = outputs.view(-1, inputs.size(1), inputs.size(2), size)\n",
    "    outputs = torch.nn.functional.pad(outputs, (b, b, 0, 0), mode='replicate')\n",
    "    return torch.cat((inputs, outputs.data))\n",
    "\n",
    "def test():\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    #running_loss = 0.0\n",
    "    #it = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion_matrix = torchnet.meter.ConfusionMeter(len(CLASSES))\n",
    "    predictions = {}\n",
    "    probabilities = {}\n",
    "\n",
    "    pbar = tqdm(test_dataloader, unit=\"audios\", unit_scale=test_dataloader.batch_size)\n",
    "    for batch in pbar:\n",
    "        inputs = batch['input']\n",
    "        inputs = torch.unsqueeze(inputs, 1)\n",
    "        targets = batch['target']\n",
    "\n",
    "        n = inputs.size(0)\n",
    "        if args.multi_crop:\n",
    "            inputs = multi_crop(inputs)\n",
    "\n",
    "        inputs = Variable(inputs, volatile = True)\n",
    "        targets = Variable(targets, requires_grad=False)\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda(async=True)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        #loss = criterion(outputs, targets)\n",
    "        outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        if args.multi_crop:\n",
    "            outputs = outputs.view(-1, n, outputs.size(1))\n",
    "            outputs = torch.mean(outputs, dim=0)\n",
    "            outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        # statistics\n",
    "        #it += 1\n",
    "        #running_loss += loss.data[0]\n",
    "        pred = outputs.data.max(1)[1]\n",
    "        #print(targets.shape, pred.shape)\n",
    "        #print((pred.data==targets.data).sum().item())\n",
    "        correct +=(pred.data==targets.data).sum().item()\n",
    "        total += targets.size(0)\n",
    "        #print(pred.shape, targets.data.shape)\n",
    "        confusion_matrix.add(pred, targets.data)\n",
    "        filenames = batch['path']\n",
    "        for j in range(len(pred)):\n",
    "            fn = filenames[j]\n",
    "            predictions[fn] = pred[j]\n",
    "            probabilities[fn] = outputs.data[j].tolist()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    #epoch_loss = running_loss / it\n",
    "    print(\"accuracy: %f%%\" % (100*accuracy))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix.value())\n",
    "\n",
    "    return probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/2944 [00:00<?, ?audios/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 128/2944 [00:00<00:13, 203.43audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 512/2944 [00:00<00:08, 277.62audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 896/2944 [00:01<00:05, 368.64audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████▎     | 1280/2944 [00:01<00:03, 479.48audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████▋    | 1664/2944 [00:01<00:02, 604.38audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████▉   | 2048/2944 [00:01<00:01, 744.25audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████▎ | 2432/2944 [00:02<00:00, 875.85audios/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 2944/2944 [00:02<00:00, 1208.80audios/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.290368%\n",
      "confusion matrix:\n",
      "[[237   0   0   2   2   4   0   3   0   0   1   8]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  4   0 248   0   0   0   2   2   0   0   0   0]\n",
      " [  6   0   0 238   0   2   2   1   1   0   0   2]\n",
      " [  2   0   0   0 264   0   1   1   1   0   1   2]\n",
      " [  3   1   0   6   0 237   0   0   1   0   0   5]\n",
      " [  2   1   4   0   1   0 258   1   0   0   0   0]\n",
      " [  6   1   0   0   0   1   1 249   0   0   0   1]\n",
      " [  3   0   0   0   0   0   2   1 239   0   0   1]\n",
      " [  1   0   0   0  11   1   1   1   8 238   0   1]\n",
      " [  1   0   0   0   1   1   2   0   0   0 244   0]\n",
      " [  4   0   0   3   1   0   2   1   1   0   0 239]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"testing...\")\n",
    "probabilities, predictions = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
