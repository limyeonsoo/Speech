{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Test a pretrained CNN for Google speech commands.\"\"\"\n",
    "\n",
    "__author__ = 'Yuan Xu, Erdene-Ochir Tuguldur'\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import *\n",
    "import torchnet\n",
    "from datasets import *\n",
    "from datasets import *\n",
    "from transforms import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['silence', '갑자기', '마그네슘', '진통제', '타이레놀', '바이러스', '내시경', '비타민', '고혈압', '단백질', '스트레스', '카페인', '다이어트', '부작용', '에너지', '아스피린']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.jit import ScriptModule, script_method, trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    __constants__ = ['downsample']\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 45\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=3, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(4, 3), stride=1, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 45, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 45, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 45, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(45 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, bias=False, padding=1)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    __constants__ = ['downsample']\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        #print(\"out {}\".format(out.shape))\n",
    "        #print(\"res {}\".format(residual.shape))\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, in_channels=1):\n",
    "        self.inplanes = 45\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, self.inplanes, kernel_size=3, stride=2, bias=False, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(4, 3), stride=1)\n",
    "        self.layer1 = self._make_layer(block, 45, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 45, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 45, layers[2], stride=2)\n",
    "        #self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(45, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        #print(downsample)\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        #x = self.layer4(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arg():\n",
    "    def __init__(self):\n",
    "        self.dataset_dir = \"/home/cilab/LabMembers/YS/Speech/health1/experiments/test\"\n",
    "        #self.dataset_dir = \"/home/cilab/LabMembers/DJ/sr_dataset/speech_command/test\"\n",
    "        self.batch_size = 16\n",
    "        self.dataload_workers_nums = 3\n",
    "        self.input = \"mel40\"\n",
    "        self.multi_crop = False\n",
    "        self.model = \"./1577452234010-resnet8-mfcc40_sgd_plateau_bs64_lr1.0e-02_wd1.0e-02-best-acc.pth\"\n",
    "\n",
    "args = Arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(1, 45, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=(4, 3), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=45, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"loading model...\")\n",
    "model = torch.load(args.model)\n",
    "model.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 45, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=(4, 3), stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=45, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = ResNet(BasicBlock, [1, 1, 1], num_classes=len(CLASSES), in_channels=3)\n",
    "#model = ResNet(BasicBlock, [2, 2, 2], num_classes=len(CLASSES))\n",
    "and_model = model.module.cpu()\n",
    "#and_model = model\n",
    "and_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.rand(1, 1, 40, 32)\n",
    "#example = torch.rand(1, 3, 224, 224)\n",
    "and_model(example)\n",
    "#traced_script_module = torch.jit.script(and_model)\n",
    "traced_script_module = torch.jit.trace(and_model, example)\n",
    "traced_script_module.save(\"./model6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 45, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=(4, 3), stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(45, 45, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=45, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8197e+00,  6.4938e-01,  1.5305e+00,  1.3726e+00,  1.1915e+00,\n",
       "         -5.3358e-01,  7.9384e-01,  1.2997e-02, -1.4025e+00, -6.4139e-01,\n",
       "          6.7175e-01,  2.0682e+00,  9.3378e-01,  2.2667e+00,  1.9986e+00,\n",
       "          7.2923e-01,  1.1790e+00,  1.1041e-01,  1.0297e+00,  1.4862e+00,\n",
       "          3.5371e-01,  1.5289e+00,  1.4979e+00,  9.7065e-01, -3.7614e-02,\n",
       "         -1.0467e-01,  1.9823e-01,  4.0023e-01, -2.4411e-01, -9.8766e-01,\n",
       "         -9.8241e-01,  8.2900e-01, -8.3933e-01,  8.4573e-01,  2.4161e+00,\n",
       "         -1.0278e+00, -6.5189e-01, -3.6844e-01,  1.1659e+00, -8.4728e-02,\n",
       "          1.9292e+00,  4.7708e-01,  1.2114e+00,  2.7290e-01,  1.3123e+00,\n",
       "          2.6466e-01,  1.6587e+00, -7.7338e-01, -2.7832e-01, -2.5070e-01,\n",
       "          1.3457e+00, -1.2550e+00,  1.3568e+00,  9.3156e-01,  4.7261e-01,\n",
       "          7.5465e-01,  2.1875e-01, -9.0694e-02,  1.0062e+00,  1.5835e+00,\n",
       "          8.5906e-01,  6.5667e-01, -3.4689e-01, -6.9891e-01,  2.8553e-01,\n",
       "          2.0191e+00,  2.0780e-02, -7.1323e-01,  5.5806e-02,  2.2712e+00,\n",
       "          1.3325e+00,  2.5539e+00,  3.5502e-01,  2.3417e+00,  6.1847e-01,\n",
       "          2.3598e+00,  9.0250e-01,  1.7827e+00,  3.5446e+00,  3.3015e+00,\n",
       "         -4.5831e-01,  1.3061e+00,  4.7698e-01, -1.7280e+00, -7.4188e-01,\n",
       "          1.2522e+00, -4.6844e-01,  2.1724e+00,  2.7592e-01,  1.8287e+00,\n",
       "         -6.1160e-01, -2.2908e-02,  2.6202e+00,  5.4127e-01,  2.7247e+00,\n",
       "         -7.1481e-01,  1.0728e+00, -1.1020e+00,  2.2569e-03,  1.9738e-01,\n",
       "          3.0827e-01, -2.0052e+00, -1.1464e+00,  9.7164e-01, -3.1867e-01,\n",
       "         -1.4876e+00, -1.5275e+00,  1.7782e+00, -1.9983e+00, -1.0185e+00,\n",
       "         -1.3803e+00,  5.0666e+00,  1.6520e+00,  9.8794e-01,  1.7563e+00,\n",
       "         -1.9289e+00, -1.8891e+00,  3.6580e-01, -4.7107e-01, -9.8179e-01,\n",
       "          3.3698e-01, -1.7885e+00, -6.4044e-01, -1.0381e+00,  6.4375e-01,\n",
       "          1.2082e+00,  1.8415e+00,  1.0980e+00,  1.1740e+00,  1.4318e+00,\n",
       "         -3.3186e-01,  7.0915e-01,  1.7166e+00,  7.7150e-01,  9.5190e-01,\n",
       "         -3.5163e-01, -5.3876e-01,  6.6235e-01,  5.8538e-01,  1.3135e+00,\n",
       "          1.0896e+00,  1.8834e+00,  3.9797e-01,  1.7024e+00,  9.7633e-01,\n",
       "         -4.6479e-01,  8.8959e-01,  2.5318e-01, -5.4752e-01, -1.9002e-01,\n",
       "         -6.2222e-01, -1.1889e-01, -2.1850e+00,  4.2132e-01, -4.3851e-01,\n",
       "         -3.5415e-01, -1.0652e+00, -9.2204e-01, -2.3056e-01, -5.4184e-01,\n",
       "         -1.7493e+00,  2.0272e-01,  4.4426e-01, -4.4552e-01,  1.3393e-01,\n",
       "         -1.3309e+00, -1.3075e-01, -2.3286e+00, -1.7425e-01, -7.9434e-01,\n",
       "         -1.0712e+00,  4.8972e-01, -1.6538e-01, -3.8600e-01, -6.7401e-01,\n",
       "         -2.2153e+00, -1.1558e+00, -1.8502e+00,  5.3537e-02, -1.0513e+00,\n",
       "         -2.9274e-01, -1.3360e+00, -5.3972e-01, -8.3538e-01, -7.6635e-01,\n",
       "         -9.5231e-01, -1.2909e+00,  5.8384e-01, -2.2552e+00, -6.0958e-01,\n",
       "         -9.4817e-01, -9.8495e-01, -2.4900e-01, -1.5912e+00, -1.8600e+00,\n",
       "          5.3642e-01,  1.5301e-01, -1.9949e+00, -1.6572e+00, -6.8674e-01,\n",
       "         -1.9265e+00, -7.4585e-01, -2.7170e-01,  7.4682e-01,  2.3863e-01,\n",
       "         -1.4674e+00, -1.5717e+00, -4.7614e-01, -9.4429e-01,  6.1453e-01,\n",
       "         -1.2209e+00, -1.3380e+00, -5.3038e-01, -8.7231e-01, -1.3195e+00,\n",
       "         -1.2383e-01, -1.8672e+00,  2.2579e-02, -4.9107e-01, -1.1162e+00,\n",
       "         -2.6870e+00, -1.2501e+00, -1.5829e+00,  1.5012e-01, -1.5259e+00,\n",
       "         -6.7233e-01, -1.5919e+00, -1.4851e+00, -2.3247e+00, -1.0623e+00,\n",
       "         -1.0516e-01, -1.6146e+00, -6.7735e-01, -3.0851e+00, -1.2324e+00,\n",
       "         -1.2683e+00, -7.1681e-01, -4.3207e-01, -5.6832e-02, -5.4919e-01,\n",
       "         -1.4322e+00, -1.2008e+00, -4.7964e-01, -1.3899e+00, -3.4298e+00,\n",
       "          3.0126e-01, -1.1519e+00, -1.0801e+00, -5.8903e-01, -5.0456e-01,\n",
       "         -7.0513e-01, -2.9081e-01, -2.3056e+00, -3.9544e-01, -6.0361e-01,\n",
       "         -3.2868e+00, -2.0172e+00, -1.0656e+00, -9.8823e-02, -8.0314e-02,\n",
       "         -1.9167e+00, -1.1859e+00, -2.9459e+00,  5.7556e-01, -2.5131e-01,\n",
       "          4.7907e-02, -3.0258e-01, -2.2132e+00, -2.0754e+00, -1.8602e+00,\n",
       "         -1.1975e+00, -1.9884e+00,  1.2001e-01,  9.6542e-02, -1.9721e+00,\n",
       "         -6.4468e-01, -9.1524e-01, -4.1726e-01, -1.0337e+00, -1.0330e-01,\n",
       "         -4.0858e-01,  3.8248e-01,  1.6805e-01, -3.7859e-02,  3.2410e-01,\n",
       "          3.4099e-01, -1.7217e+00, -1.6666e+00, -2.1589e+00, -2.2777e+00,\n",
       "         -2.6684e+00, -1.8142e+00, -1.8438e+00, -1.0769e+00, -1.9896e+00,\n",
       "         -1.2671e+00, -1.0606e+00, -2.6002e+00, -5.9238e-01, -6.5275e-01,\n",
       "         -6.7200e-01,  2.1539e+00,  7.9807e-01,  1.8973e+00,  7.4094e-01,\n",
       "          3.0741e-01,  1.3424e+00,  1.6615e+00,  1.7153e+00, -2.0316e-01,\n",
       "          2.3774e+00,  1.6153e+00,  2.0300e+00,  3.0828e+00,  2.6966e+00,\n",
       "          2.4349e+00,  2.5584e+00,  2.4925e+00,  3.7820e+00,  1.9893e+00,\n",
       "          1.7257e+00, -1.0221e+00, -2.0938e+00, -5.0495e-01,  9.5476e-02,\n",
       "         -4.5898e-01,  2.3794e-01,  1.8067e+00, -9.1698e-02, -7.4687e-01,\n",
       "         -3.0968e-01,  1.9997e-01, -2.2950e-01, -5.0871e-01, -9.7461e-01,\n",
       "         -8.4164e-01, -1.8447e+00, -8.8169e-01, -9.4426e-01, -2.1897e+00,\n",
       "         -2.0095e+00, -3.5485e+00, -2.1471e+00, -1.3140e+00, -1.2699e+00,\n",
       "         -2.0800e+00, -9.7441e-01, -1.4769e+00, -2.3936e+00, -9.9666e-01,\n",
       "         -6.4190e-01, -4.5369e-01, -1.0983e+00, -2.1804e-01, -1.1932e+00,\n",
       "         -3.4316e+00,  6.1222e-01, -5.6649e-01, -1.0178e-01,  6.6415e-01,\n",
       "         -9.9363e-01,  1.0795e+00, -3.7528e-01,  4.6274e-01, -7.3814e-01,\n",
       "         -1.6040e+00, -2.4244e+00, -7.6361e-01, -1.9849e+00, -2.0602e+00,\n",
       "         -1.1691e+00, -2.3613e+00, -1.7654e+00, -1.3440e+00, -3.5038e-01,\n",
       "         -1.7173e+00, -5.8956e-01, -1.7565e-01, -1.4429e+00, -2.1207e+00,\n",
       "         -1.8317e+00, -1.1764e+00, -8.2777e-01, -7.0186e-01, -2.1011e+00,\n",
       "         -2.3032e+00, -1.8038e+00, -2.2637e+00, -2.1717e+00, -1.0410e+00,\n",
       "         -7.0127e-01,  2.7246e-01, -1.8891e+00, -1.7746e+00, -6.4777e-01,\n",
       "          1.0980e+00,  1.6011e-01,  1.9120e-01, -2.4368e-01,  6.6363e-02,\n",
       "         -1.9618e+00, -1.0021e+00,  1.9045e+00,  1.3015e+00,  1.0389e+00,\n",
       "          2.2155e+00, -1.0904e+00, -1.4814e+00, -1.8853e+00,  1.6358e+00,\n",
       "         -9.3951e-01,  4.8144e-02,  2.7817e-01,  8.9310e-01, -1.9988e-01,\n",
       "         -2.3576e+00,  3.3655e-01,  1.2848e+00,  4.8315e+00,  1.6361e+00,\n",
       "          1.1332e+00,  2.4269e-01,  3.9028e-01, -2.0034e+00, -2.3323e+00,\n",
       "         -8.1666e-01,  1.0859e+00, -5.4410e-01, -1.1684e+00,  1.3276e+00,\n",
       "         -1.0058e+00, -1.1493e+00,  1.5279e+00, -8.9849e-02,  1.8600e-01,\n",
       "         -1.1900e+00, -6.1076e-01,  7.8144e-01,  2.1077e-01, -1.5722e+00,\n",
       "          1.7147e+00,  1.0178e+00, -4.3135e-01,  1.8600e+00, -3.3793e-01,\n",
       "         -4.1076e-01,  2.9299e+00, -5.9463e-01,  1.0115e+00, -8.0372e-01,\n",
       "         -8.3072e-01,  2.6823e+00, -2.0534e-01, -2.5806e-01, -1.5633e+00,\n",
       "          2.7540e+00,  6.8280e-01,  5.2523e-01,  1.0994e+00,  2.4195e-01,\n",
       "          1.4270e+00, -6.1921e-01,  1.7255e+00,  3.8111e-01,  1.5735e+00,\n",
       "         -2.5239e-01, -1.3366e+00, -2.9603e+00, -4.7669e-01, -1.1389e+00,\n",
       "          1.5627e+00,  4.3278e-02, -1.2898e-01,  2.1093e+00,  7.2052e-01,\n",
       "         -1.2265e+00, -3.9066e+00, -3.2391e-01,  1.6658e+00, -5.1844e-01,\n",
       "          5.8244e-01,  2.1742e+00, -2.7949e-02, -7.7302e-01,  4.8968e-01,\n",
       "          1.1864e+00, -1.3916e-01,  1.6201e+00,  2.3115e+00, -5.0969e-01,\n",
       "          2.9183e-01,  4.2439e-01,  9.5616e-01, -1.1039e+00,  2.8531e-01,\n",
       "         -7.1080e-01,  1.0085e+00, -1.1442e+00, -1.6804e-01,  1.4055e+00,\n",
       "         -7.3804e-01, -3.3972e-01,  3.3168e-01,  5.7599e-01,  8.2409e-01,\n",
       "          8.8433e-01,  7.6708e-02,  1.4929e+00,  3.3358e-01, -2.9598e+00,\n",
       "          2.4938e-01, -1.0803e+00,  2.8754e+00,  2.7216e-01,  1.9924e-01,\n",
       "          3.3780e-01, -1.6454e+00,  1.2209e+00, -9.7192e-01, -6.3257e-01,\n",
       "         -1.1018e+00, -1.0975e+00, -3.7308e-01,  1.6096e+00, -1.3628e+00,\n",
       "         -1.2670e+00,  1.0742e-01, -8.4369e-01,  2.1421e-01,  2.8814e-01,\n",
       "          1.9894e+00,  8.2871e-01, -6.5045e-01,  1.4615e+00,  3.3070e-01,\n",
       "         -1.4366e+00, -9.5176e-01, -6.4161e-01,  5.6327e-01,  4.0530e-01,\n",
       "          9.2702e-01,  9.4572e-02,  1.9336e+00,  1.7860e-01, -6.7875e-01,\n",
       "          1.4318e+00,  1.9656e-01, -2.6134e+00, -3.2703e-01,  3.6275e+00,\n",
       "         -1.7033e+00, -4.4301e-01,  4.9638e-01,  1.1986e+00,  3.6575e-01,\n",
       "         -1.5185e+00,  7.2070e-01,  1.0819e+00,  1.3630e+00,  1.0418e+00,\n",
       "         -6.5660e-01, -5.1091e-01, -3.3372e-01,  4.0236e+00, -1.8173e+00,\n",
       "         -1.1246e+00, -5.6231e-01,  7.1624e-01, -1.1468e+00, -1.9304e+00,\n",
       "         -2.4210e-01, -1.8769e+00,  1.5156e+00,  2.8691e-02,  2.4141e+00,\n",
       "         -1.9302e+00, -1.7921e+00, -7.0561e-01, -6.9014e-01, -7.8958e-01,\n",
       "         -2.6981e+00, -1.2355e+00, -2.7938e+00,  4.8076e-01,  2.6786e+00,\n",
       "          3.3270e-01, -5.4454e-01,  2.3976e+00,  2.8612e-01,  9.7843e-01,\n",
       "         -1.2289e+00,  2.0133e+00,  1.2220e+00,  1.4200e+00, -1.0049e-01,\n",
       "         -1.8141e+00,  1.1969e+00,  1.4735e+00,  7.8295e-02, -4.3870e-01,\n",
       "          3.1079e+00,  2.7312e-01,  2.4631e-01, -2.3382e+00,  1.7343e+00,\n",
       "          2.6386e+00,  1.9899e+00,  1.7106e-01,  1.4757e+00, -1.7898e+00,\n",
       "          1.6040e+00,  2.5428e+00, -2.0478e+00,  2.0002e+00, -8.7506e-01,\n",
       "          5.5441e-02,  3.6430e+00, -6.3116e-01,  2.9063e+00,  2.5579e+00,\n",
       "          2.6507e+00, -1.2236e+00,  2.7737e+00,  3.8117e+00, -4.6424e-01,\n",
       "         -3.4350e-01,  2.6846e+00, -9.6715e-01,  1.0635e+00,  2.1701e+00,\n",
       "         -2.3217e-02,  8.4696e-01,  1.2488e+00,  1.3231e+00, -3.8832e+00,\n",
       "          9.8493e-01,  5.9582e-03, -1.4392e-02, -1.2429e-01, -3.9084e-01,\n",
       "          4.4707e-01,  4.5182e-01, -1.4174e+00,  5.1374e-01,  4.5374e+00,\n",
       "         -1.0471e+00, -6.2797e-01,  5.7048e-01, -5.6913e-01, -8.0095e-01,\n",
       "          1.9362e+00, -9.8453e-01, -5.0449e-01, -1.6374e-01, -1.5477e+00,\n",
       "          8.3538e-01, -1.5017e+00,  3.0045e+00,  2.7876e-01,  8.6201e-01,\n",
       "         -9.1699e-01, -2.2562e+00,  2.4852e+00, -1.8932e+00,  1.4019e+00,\n",
       "          3.2251e-01,  5.4366e-01,  1.4884e-01, -2.3841e-01, -1.7023e-01,\n",
       "         -1.3556e+00, -1.4716e+00, -1.4102e-01,  2.1663e+00,  2.6988e+00,\n",
       "         -1.8061e+00, -1.3589e+00,  3.3238e+00, -6.3591e-01,  3.6248e+00,\n",
       "          9.7644e-01,  2.5922e+00,  1.9133e+00,  1.4401e+00,  1.5259e+00,\n",
       "          5.5179e-01, -1.5932e-01, -2.4268e+00,  1.0010e+00, -1.2368e+00,\n",
       "         -2.6717e+00, -4.7056e-02,  1.3364e+00,  3.3250e-01, -9.6325e-01,\n",
       "          1.4035e+00,  1.8176e+00,  1.3317e-01, -1.7237e+00,  4.4646e-01,\n",
       "          2.2002e+00,  2.5791e+00, -3.3011e-01, -1.3919e+00,  6.7057e-01,\n",
       "         -2.2570e+00, -8.9437e-01, -2.3619e-01, -2.6843e-01,  1.9324e+00,\n",
       "          2.1390e+00,  1.6645e+00,  1.3020e+00, -5.9003e-02,  2.9759e+00,\n",
       "         -1.3131e+00,  4.5377e-01, -2.3253e+00,  7.2303e-01,  1.2699e+00,\n",
       "          2.6359e+00,  1.1156e+00,  2.7975e+00,  9.8103e-01,  1.6870e-01,\n",
       "          1.5285e+00,  1.2163e-01,  5.6500e-01,  4.9841e-01, -5.2167e-01,\n",
       "         -1.0265e+00,  1.4755e+00,  2.1316e-01,  2.0219e+00, -2.3457e+00,\n",
       "          1.3316e+00,  2.1539e+00,  1.8167e+00,  7.5684e-01, -3.8350e+00,\n",
       "          8.5223e-01,  2.8513e-01, -4.2756e-01, -9.2780e-01,  2.0589e+00,\n",
       "          7.1369e-01,  1.5921e+00, -2.4484e-01,  9.9103e-01,  3.0095e+00,\n",
       "         -1.9348e-01, -7.0200e-01,  2.5665e+00,  1.3361e+00, -9.0902e-02,\n",
       "          2.5199e-01, -1.2740e+00, -1.9294e+00, -2.1326e-02,  1.1372e+00,\n",
       "          4.4639e-01,  2.0571e+00, -2.4693e+00,  3.3752e+00,  9.8801e-01,\n",
       "          2.2545e-01, -2.8368e+00,  3.5456e+00, -4.5181e-01,  3.3639e+00,\n",
       "          1.1549e+00,  1.1631e+00,  2.7635e+00,  2.3614e+00,  1.3083e+00,\n",
       "         -3.3803e-01,  9.0054e-01,  2.2455e+00, -2.5343e-01, -1.8285e+00,\n",
       "          5.5825e-01, -7.0455e-01,  1.5406e+00,  4.0628e+00,  4.0486e+00,\n",
       "         -1.0392e+00,  3.6670e-01, -7.9117e-01, -1.8550e+00,  4.7357e-02,\n",
       "         -1.0190e+00,  9.0792e-01,  2.8369e-01,  3.9021e-01,  8.8575e-02,\n",
       "          8.2307e-01,  1.6955e-01, -8.0611e-01,  1.7500e+00,  1.9379e-01,\n",
       "         -2.3860e+00,  5.9108e-01, -1.1826e+00, -3.7543e-01,  1.7057e+00,\n",
       "          6.2019e-01,  6.0372e-01, -2.2973e+00, -4.1366e-01,  9.6325e-01,\n",
       "         -7.3576e-01,  1.2469e+00,  2.6118e+00,  1.6946e+00,  6.0610e-01,\n",
       "          7.5581e-01,  1.8362e+00, -2.2705e+00,  2.3781e+00, -7.7679e-01,\n",
       "         -2.9291e+00, -7.4026e-01, -1.3254e+00,  2.6201e-01,  7.5901e-02,\n",
       "         -1.8999e+00,  1.4378e+00, -1.2174e+00,  1.9928e+00, -2.4283e+00,\n",
       "         -6.5732e-01, -4.8579e-01, -1.1671e+00,  1.0902e+00,  5.1210e-01,\n",
       "         -7.1432e-01, -2.4320e-01,  9.3794e-01, -6.6878e-02,  2.2821e-01,\n",
       "          1.2254e+00,  3.6309e-01,  2.4213e-01, -1.0377e+00,  3.8302e+00,\n",
       "          4.7821e+00,  2.4937e+00, -1.0323e+00,  8.7119e-01,  9.4654e-01,\n",
       "         -3.7112e-03,  1.2114e+00,  3.0116e+00, -6.2995e-01, -1.4292e+00,\n",
       "          3.0634e+00, -3.8521e+00, -1.6857e+00, -3.1857e-01,  3.4146e-01,\n",
       "         -2.5684e+00,  2.9876e-01,  1.2474e+00, -1.5879e-01, -1.7110e+00,\n",
       "         -3.9059e+00, -1.7212e+00, -1.2963e+00,  1.4717e+00,  3.4692e-01,\n",
       "          4.7215e-01,  2.8541e-01,  2.1001e+00,  5.3503e-01, -2.8720e+00,\n",
       "         -1.3948e-01, -5.3622e-01, -1.6319e+00, -1.3776e+00,  1.3817e+00,\n",
       "          1.0626e+00, -8.1324e-01,  1.4350e+00,  1.7663e+00, -3.0068e-01,\n",
       "          7.7065e-01, -1.9422e+00, -1.8650e+00, -6.7261e-01,  3.4849e-02,\n",
       "         -5.4383e-01, -6.2187e-01,  4.6336e+00,  2.8006e+00, -7.2234e-01,\n",
       "          1.1963e+00, -7.2112e-02, -9.7422e-01,  1.4843e+00,  7.4416e-01,\n",
       "          5.0095e-01,  5.5623e-01,  2.6354e+00,  8.1927e-02,  1.7988e+00,\n",
       "          5.4782e-02, -5.8624e-01,  9.9281e-01,  1.6941e+00, -3.3195e-02,\n",
       "          1.4295e+00,  6.6739e-01, -2.0447e+00,  7.9027e-01, -5.8504e-01,\n",
       "         -1.2981e+00, -1.3420e+00, -9.7631e-01, -2.2542e-01,  5.9006e-01,\n",
       "          1.2330e+00,  1.5814e+00,  8.1717e-01, -8.3012e-01, -1.4537e+00,\n",
       "         -5.4018e-01, -3.2533e+00,  1.9300e-01, -1.9432e-02,  1.3039e+00,\n",
       "         -1.1533e+00, -6.5947e-01, -9.3516e-02, -1.7854e+00, -1.7305e+00,\n",
       "         -1.2552e+00, -2.1562e+00,  2.6841e-01, -1.0755e+00, -3.2683e-01,\n",
       "         -6.0313e-01, -1.5051e+00, -1.2039e+00, -9.1895e-01, -2.0744e+00,\n",
       "         -2.4362e-01, -2.2636e+00, -1.9758e+00,  1.0224e+00,  4.0821e-01,\n",
       "          9.2649e-01,  1.0695e+00,  8.2941e-02, -5.2484e-02,  8.9883e-01,\n",
       "         -1.7003e+00, -1.6334e+00,  3.6394e-01, -6.3130e-01, -4.2083e-01,\n",
       "         -3.8854e-01,  4.1176e-01, -1.5789e+00,  5.7011e-01, -7.6849e-01,\n",
       "         -1.7062e+00,  1.1985e+00,  1.2873e+00,  1.5522e+00, -4.6267e-01,\n",
       "         -1.7535e+00,  1.5366e+00,  4.0068e-02, -1.2657e+00, -4.6501e-01,\n",
       "          1.0619e+00,  1.3077e+00,  2.0040e+00,  1.4214e+00, -1.4625e+00,\n",
       "          1.5796e+00,  7.2576e-01, -1.6160e+00,  1.2486e-01, -2.8301e-01,\n",
       "          8.9161e-03, -1.0677e+00,  1.6173e-01,  8.4883e-01,  1.5315e-01,\n",
       "          1.6442e-01, -1.8532e+00, -1.9246e+00, -3.0729e+00, -2.3304e+00,\n",
       "         -1.8257e+00, -2.4333e+00, -1.1257e+00, -2.9253e-01,  2.6386e+00]],\n",
       "       grad_fn=<DifferentiableGraphBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227356"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu True\n",
      "40\n",
      "all :  ['갑자기', '마그네슘', '진통제', '타이레놀', '바이러스', '내시경', '비타민', '고혈압', '단백질', '스트레스', '카페인', '다이어트', '부작용', '에너지', '아스피린']\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('use_gpu', use_gpu)\n",
    "if use_gpu:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model.cuda()\n",
    "\n",
    "n_mels = 20\n",
    "if args.input == 'mel40':\n",
    "    n_mels = 40\n",
    "print(n_mels)\n",
    "dataset_dir = args.dataset_dir\n",
    "feature_transform = Compose([ToMfcc(n_mels=n_mels), ToTensor('mfcc', 'input')])\n",
    "transform = Compose([LoadAudio(), FixAudioLength(), feature_transform])\n",
    "test_dataset = SpeechCommandsDataset(dataset_dir, transform, silence_percentage=0, classes=CLASSES)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, sampler=None,\n",
    "                            pin_memory=use_gpu, num_workers=args.dataload_workers_nums)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_crop(inputs):\n",
    "    b = 1\n",
    "    size = inputs.size(3) - b * 2\n",
    "    patches = [inputs[:, :, :, i*b:size+i*b] for i in range(3)]\n",
    "    outputs = torch.stack(patches)\n",
    "    outputs = outputs.view(-1, inputs.size(1), inputs.size(2), size)\n",
    "    outputs = torch.nn.functional.pad(outputs, (b, b, 0, 0), mode='replicate')\n",
    "    return torch.cat((inputs, outputs.data))\n",
    "\n",
    "def test():\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    #running_loss = 0.0\n",
    "    #it = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion_matrix = torchnet.meter.ConfusionMeter(len(CLASSES))\n",
    "    predictions = {}\n",
    "    probabilities = {}\n",
    "\n",
    "    pbar = tqdm(test_dataloader, unit=\"audios\", unit_scale=test_dataloader.batch_size)\n",
    "    for batch in pbar:\n",
    "        inputs = batch['input']\n",
    "        print(inputs[0][22])\n",
    "        inputs = torch.unsqueeze(inputs, 1)\n",
    "        targets = batch['target']\n",
    "\n",
    "        n = inputs.size(0)\n",
    "        if args.multi_crop:\n",
    "            inputs = multi_crop(inputs)\n",
    "\n",
    "        inputs = Variable(inputs, volatile = True)\n",
    "        targets = Variable(targets, requires_grad=False)\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda(async=True)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        #loss = criterion(outputs, targets)\n",
    "        outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        \n",
    "        if args.multi_crop:\n",
    "            outputs = outputs.view(-1, n, outputs.size(1))\n",
    "            outputs = torch.mean(outputs, dim=0)\n",
    "            outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "        # statistics\n",
    "        #it += 1\n",
    "        #running_loss += loss.data[0]\n",
    "        pred = outputs.data.max(1)[1]\n",
    "        #print(targets.shape, pred.shape)\n",
    "        #print((pred.data==targets.data).sum().item())\n",
    "        correct +=(pred.data==targets.data).sum().item()\n",
    "        total += targets.size(0)\n",
    "        #print(pred.shape, targets.data.shape)\n",
    "        confusion_matrix.add(pred, targets.data)\n",
    "        filenames = batch['path']\n",
    "        for j in range(len(pred)):\n",
    "            fn = filenames[j]\n",
    "            predictions[fn] = pred[j]\n",
    "            probabilities[fn] = outputs.data[j].tolist()\n",
    "\n",
    "    accuracy = correct/total\n",
    "    #epoch_loss = running_loss / it\n",
    "    print(\"accuracy: %f%%\" % (100*accuracy))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix.value())\n",
    "\n",
    "    return probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.32614076  0.3541311  -0.60259877  0.34045089]\n",
      " [ 1.08952646  0.52263315 -0.18174121  1.92901391]\n",
      " [ 1.08429475  0.7643971  -0.78600618 -0.17234044]]\n",
      "********************************************************************************\n",
      "[[-0.32614076  0.3541311  -0.60259877  0.34045089  0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 1.08952646  0.52263315 -0.18174121  1.92901391  0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 1.08429475  0.7643971  -0.78600618 -0.17234044  0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randn(3, 4)\n",
    "print(A)\n",
    "print('*'*80)\n",
    "print(np.pad(A, (0, 10-len(A)), \"constant\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/48 [00:00<?, ?audios/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "\r",
      " 33%|███▎      | 16/48 [00:00<00:01, 28.18audios/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.0000,   0.0000,   0.0000,   0.0000,  -8.3432,  -9.2647,  -4.3395,\n",
      "         -2.1458,  -2.5516,  -3.6802,  -8.3702, -12.6168,  -7.1699,  -3.6953,\n",
      "         -5.3297,  -1.5755,  -8.6389,  -6.7047,  -5.7460,  -4.2749,  -2.0911,\n",
      "         -3.2767,  -3.7439,  -9.4927, -10.2967, -10.4862,  -8.1637,  -2.0664,\n",
      "         -0.0829,   0.0000,   0.0000,   0.0000])\n",
      "tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  -0.9327,\n",
      "         -2.8921,  -2.8934,  -1.6885,  -1.6049,  -5.7880,  -3.1092,  -6.9222,\n",
      "        -11.8785, -19.5574, -24.3977, -27.6595, -26.5008, -24.5870, -22.0126,\n",
      "        -16.5154, -13.9178,  -8.7657,  -4.5640,   3.9064,   0.0000,   0.0000,\n",
      "          0.0000,   0.0000,   0.0000,   0.0000])\n",
      "tensor([  0.0000,   0.0000,   0.0000,   0.0000,   1.8384,   2.4731,  -4.4479,\n",
      "         -1.9339,  -0.0639,   0.5009, -11.4196, -10.4551, -11.2042,  -4.9648,\n",
      "         -2.8452,  -3.7632, -10.1172,  -2.0366,  -3.6482,  -5.7489,  -8.4998,\n",
      "        -10.2675,  -9.3854,  -6.3409,  -6.6455,  -4.5881,  -2.7581,  -4.0722,\n",
      "          0.2854,   0.0000,   0.0000,   0.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 48/48 [00:00<00:00, 62.30audios/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 68.750000%\n",
      "confusion matrix:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  2  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  1  0  0  0  6  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  2  0  1  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"testing...\")\n",
    "probabilities, predictions = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
